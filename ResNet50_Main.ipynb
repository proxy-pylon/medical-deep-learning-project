{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDgA1bB-A9Eb"
      },
      "source": [
        "# ResNet-50 Skin Cancer Classifier with Advanced Training Techniques\n",
        "## ISIC Dataset (Stratified 5-Fold CV with Clinical Validation)\n",
        "\n",
        "This notebook implements a production-ready skin cancer classifier with:\n",
        "- Progressive layer unfreezing with discriminative learning rates\n",
        "- Learning rate warmup (5 epochs) and cosine annealing\n",
        "- Gradient clipping (max_norm=1.0)\n",
        "- Stratified 5-fold cross-validation\n",
        "- Bootstrap confidence intervals\n",
        "- Focal Loss for class imbalance\n",
        "- Temperature scaling calibration\n",
        "- Per-class performance thresholds (melanoma F1 > 0.90)\n",
        "- Comprehensive error analysis and clinical expert review\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from IPython import get_ipython\n",
        "if get_ipython():\n",
        "    get_ipython().kernel.do_shutdown(restart=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c:\\Users\\elzha\\Desktop\\CSCI 494 DL\\GroupProject\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())\n",
        "\n",
        "os.chdir('C:\\\\Users\\\\elzha\\\\Desktop\\\\CSCI 494 DL\\\\GroupProject')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m venv .venvNew "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The system cannot find the path specified.\n"
          ]
        }
      ],
      "source": [
        "!.venv\\Scripts\\activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aC6e4WxcA9Ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu121, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: torch in c:\\users\\elzha\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in c:\\users\\elzha\\anaconda3\\lib\\site-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: torchaudio in c:\\users\\elzha\\anaconda3\\lib\\site-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: setuptools in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from torchvision) (12.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "CUDA available in PyTorch: True\n",
            "PyTorch CUDA version: 12.1\n",
            "Number of GPUs detected: 1\n",
            "GPU Name: NVIDIA GeForce RTX 4070 SUPER\n",
            "GPU Compute Capability: (8, 9)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available in PyTorch: {torch.cuda.is_available()}\")\n",
        "print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "print(f\"Number of GPUs detected: {torch.cuda.device_count()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Compute Capability: {torch.cuda.get_device_capability(0)}\")\n",
        "else:\n",
        "    print(\"GPU not detected - check hardware/drivers.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIyxHnRHA9Ed",
        "outputId": "3e0399cc-e583-47b6-fb2d-05ece18aa1c3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.5.1+cu121\n",
            "GPU available: True\n",
            "GPU: NVIDIA GeForce RTX 4070 SUPER\n"
          ]
        }
      ],
      "source": [
        "# Imports\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, List, Optional, Tuple, Union\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from numpy.typing import ArrayLike\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, Subset\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    roc_auc_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    roc_curve,\n",
        "    auc,\n",
        "    brier_score_loss,\n",
        "    log_loss,\n",
        "    precision_recall_curve,\n",
        "    classification_report\n",
        ")\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "sns.set_style('whitegrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"GPU available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
            "Requirement already satisfied: kagglehub in c:\\users\\elzha\\anaconda3\\lib\\site-packages (0.2.2)\n",
            "Requirement already satisfied: requests in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from kagglehub) (2.32.3)\n",
            "Requirement already satisfied: tqdm in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from kagglehub) (4.66.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from requests->kagglehub) (2025.10.5)\n",
            "Requirement already satisfied: colorama in c:\\users\\elzha\\anaconda3\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install kagglehub "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuoVBlEdA9Ee",
        "outputId": "c0ba511e-92e8-450d-abe8-66074bc64d3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Directories created\n",
            "Device: cuda\n",
            "Data directory: C:\\Users\\elzha\\isic_data\n",
            "Output directory: C:\\Users\\elzha\\melanoma_results\n",
            "Random seed used for initialization: 42\n"
          ]
        }
      ],
      "source": [
        "# Configuration\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration container for training and model parameters.\"\"\"\n",
        "\n",
        "    # Dataset - Using local paths\n",
        "    home_dir = str(Path.home())\n",
        "    ISIC_DATASET_URL = 'https://api.isic-archive.com/collections/66/'\n",
        "    DATA_DIR = os.path.join(home_dir, 'isic_data')\n",
        "    OUTPUT_DIR = os.path.join(home_dir, 'melanoma_results')\n",
        "    CHECKPOINT_DIR = os.path.join(OUTPUT_DIR, 'checkpoints')\n",
        "    RESULTS_DIR = os.path.join(OUTPUT_DIR, 'results')\n",
        "\n",
        "    # Model\n",
        "    MODEL_NAME = 'resnet50'\n",
        "    IMG_SIZE = 224\n",
        "    NUM_CLASSES = 2  # Binary: melanoma vs non-melanoma\n",
        "    PRETRAINED = True\n",
        "\n",
        "    # Training (IMPROVED)\n",
        "    BATCH_SIZE = 64  # ↑ 2x larger for stable gradients\n",
        "    MAX_EPOCHS = 150  # ↑ 50% more epochs\n",
        "    WARMUP_EPOCHS = 8\n",
        "    EARLY_STOPPING_PATIENCE = 20  # ↑ More patience\n",
        "    \n",
        "    # Learning rates (IMPROVED: 5-10x higher)\n",
        "    HEAD_LR = 5e-3       # ↑ 5x increase\n",
        "    BACKBONE_LR_LOW = 5e-5    # ↑ 5x increase\n",
        "    BACKBONE_LR_MID = 1e-4    # ↑ 5x increase\n",
        "    BACKBONE_LR_HIGH = 5e-4   # ↑ 10x increase\n",
        "    WEIGHT_DECAY = 5e-5  # ↓ 50% reduction (less regularization)\n",
        "    \n",
        "    # Regularization (IMPROVED)\n",
        "    DROPOUT = 0.3  # ↓ 40% reduction to prevent underfitting\n",
        "    GRADIENT_CLIP = 1.0\n",
        "    LABEL_SMOOTHING = 0.1  # NEW for calibration\n",
        "\n",
        "    # Validation\n",
        "    TEST_SIZE = 0.2\n",
        "    N_SPLITS = 5  # For 5-fold CV\n",
        "    RANDOM_STATE = SEED\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    NUM_WORKERS = 0  # Set to 0 for Windows compatibility\n",
        "\n",
        "    # Performance thresholds\n",
        "    MIN_MELANOMA_F1 = 0.90\n",
        "\n",
        "    # Bootstrap\n",
        "    N_BOOTSTRAP_SAMPLES = 1000\n",
        "    CI_LEVEL = 0.95\n",
        "\n",
        "config = Config()\n",
        "os.makedirs(config.CHECKPOINT_DIR, exist_ok=True)\n",
        "os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
        "os.makedirs(config.DATA_DIR, exist_ok=True)\n",
        "\n",
        "print(f\"✓ Directories created\")\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"Data directory: {config.DATA_DIR}\")\n",
        "print(f\"Output directory: {config.OUTPUT_DIR}\")\n",
        "print(f\"Random seed used for initialization: {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVyeNTTnA9Ee",
        "outputId": "b0e9ed24-2dac-4fb2-b756-9f1e0d52db57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading HAM10000 dataset from local cache...\n",
            "Path: C:\\Users\\elzha\\.cache\\kagglehub\\datasets\\kmader\\skin-cancer-mnist-ham10000\\versions\\2\n",
            "\n",
            "✓ Loaded 10015 images with verified paths\n",
            "\n",
            "Diagnosis distribution:\n",
            "{'nv': 6705, 'mel': 1113, 'bkl': 1099, 'bcc': 514, 'akiec': 327, 'vasc': 142, 'df': 115}\n",
            "\n",
            "Melanoma (binary_label=1): 1113\n",
            "Non-melanoma (binary_label=0): 8902\n",
            "\n",
            "✓ Dataset ready for training: 10015 images\n"
          ]
        }
      ],
      "source": [
        "# Load HAM10000 dataset from local cache\n",
        "def load_ham10000_dataset_local(dataset_path: str) -> pd.DataFrame:\n",
        "    \"\"\"Load HAM10000 dataset directly from local cache path.\"\"\"\n",
        "    import os\n",
        "    from pathlib import Path\n",
        "    \n",
        "    print(f\"Loading HAM10000 dataset from local cache...\")\n",
        "    print(f\"Path: {dataset_path}\")\n",
        "    print()\n",
        "    \n",
        "    try:\n",
        "        # Verify the path exists\n",
        "        if not os.path.exists(dataset_path):\n",
        "            print(f\"❌ Dataset path does not exist: {dataset_path}\")\n",
        "            print()\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # Load metadata\n",
        "        metadata_path = os.path.join(dataset_path, 'HAM10000_metadata.csv')\n",
        "        if not os.path.exists(metadata_path):\n",
        "            print(f\"❌ Metadata file not found: {metadata_path}\")\n",
        "            print()\n",
        "            return pd.DataFrame()\n",
        "            \n",
        "        df = pd.read_csv(metadata_path)\n",
        "        \n",
        "        # Find image directories (handles different naming conventions)\n",
        "        image_dirs = []\n",
        "        for dir_name in ['HAM10000_images_part_1', 'HAM10000_images_part_2',\n",
        "                         'ham10000_images_part_1', 'ham10000_images_part_2']:\n",
        "            dir_path = os.path.join(dataset_path, dir_name)\n",
        "            if os.path.exists(dir_path):\n",
        "                image_dirs.append(dir_path)\n",
        "        \n",
        "        if not image_dirs:\n",
        "            print(\"⚠️  No image directories found!\")\n",
        "            print(f\"Contents of {dataset_path}:\")\n",
        "            print(os.listdir(dataset_path))\n",
        "            return pd.DataFrame()\n",
        "        \n",
        "        # Resolve full image paths\n",
        "        def get_image_path(image_id):\n",
        "            for img_dir in image_dirs:\n",
        "                img_path = os.path.join(img_dir, f'{image_id}.jpg')\n",
        "                if os.path.exists(img_path):\n",
        "                    return img_path\n",
        "            return None\n",
        "        \n",
        "        df['image_path'] = df['image_id'].apply(get_image_path)\n",
        "        df = df[df['image_path'].notna()].reset_index(drop=True)\n",
        "        \n",
        "        # Create binary labels (melanoma vs non-melanoma)\n",
        "        df['binary_label'] = (df['dx'] == 'mel').astype(int)\n",
        "        \n",
        "        # Rename diagnosis to match expected format\n",
        "        df['diagnosis'] = df['dx']\n",
        "        \n",
        "        print(f\"✓ Loaded {len(df)} images with verified paths\")\n",
        "        print()\n",
        "        print(\"Diagnosis distribution:\")\n",
        "        print(df['diagnosis'].value_counts().to_dict())\n",
        "        print()\n",
        "        print(f\"Melanoma (binary_label=1): {(df['binary_label'] == 1).sum()}\")\n",
        "        print(f\"Non-melanoma (binary_label=0): {(df['binary_label'] == 0).sum()}\")\n",
        "        \n",
        "        return df[['image_id', 'image_path', 'binary_label', 'diagnosis']].reset_index(drop=True)\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error loading dataset: {e}\")\n",
        "        print()\n",
        "        return pd.DataFrame()\n",
        "\n",
        "\n",
        "# Load dataset from specified local path\n",
        "DATASET_PATH = r'C:\\Users\\elzha\\.cache\\kagglehub\\datasets\\kmader\\skin-cancer-mnist-ham10000\\versions\\2'\n",
        "df_isic = load_ham10000_dataset_local(DATASET_PATH)\n",
        "\n",
        "if df_isic.empty:\n",
        "    print()\n",
        "    print(\"⚠️  Could not load dataset. Please check the path and try again.\")\n",
        "    print()\n",
        "    use_ham10000 = False\n",
        "else:\n",
        "    print()\n",
        "    print(f\"✓ Dataset ready for training: {len(df_isic)} images\")\n",
        "    use_ham10000 = True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppXAzKHOA9Ee",
        "outputId": "27a6f969-f379-4b7d-ffd7-768669fba73c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Dataset class and transforms defined\n"
          ]
        }
      ],
      "source": [
        "# Dataset class\n",
        "class SkinCancerDataset(Dataset):\n",
        "    \"\"\"PyTorch Dataset for skin cancer classification.\"\"\"\n",
        "\n",
        "    def __init__(self, dataframe: pd.DataFrame, transform: Optional[A.Compose] = None):\n",
        "        self.df = dataframe.reset_index(drop=True)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
        "        img_path = self.df.loc[idx, 'image_path']\n",
        "        label = int(self.df.loc[idx, 'binary_label'])\n",
        "\n",
        "        # Load image\n",
        "        image = cv2.imread(str(img_path))\n",
        "        if image is None:\n",
        "            # Fallback: create dummy image\n",
        "            image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
        "        else:\n",
        "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        # Apply transforms\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image=image)\n",
        "            image = augmented['image']\n",
        "\n",
        "        return {\n",
        "            'image': image,\n",
        "            'label': torch.tensor(label, dtype=torch.long),\n",
        "            'image_id': self.df.loc[idx, 'image_id'] if 'image_id' in self.df.columns else str(idx)\n",
        "        }\n",
        "\n",
        "# Augmentation pipelines\n",
        "def get_train_transforms(img_size: int = 224) -> A.Compose:\n",
        "    return A.Compose([\n",
        "        A.RandomResizedCrop(size=(img_size, img_size), scale=(0.8, 1.0), p=1.0),\n",
        "        A.HorizontalFlip(p=0.5),\n",
        "        A.VerticalFlip(p=0.5),\n",
        "        A.Rotate(limit=30, border_mode=cv2.BORDER_REFLECT_101, p=0.7),\n",
        "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "        A.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.05, p=0.3),\n",
        "        A.GaussNoise(p=0.2),\n",
        "        A.Blur(blur_limit=3, p=0.2),\n",
        "        A.CoarseDropout(max_holes=1, max_height=int(0.1*img_size), max_width=int(0.1*img_size), p=0.2),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "def get_val_transforms(img_size: int = 224) -> A.Compose:\n",
        "    return A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "        ToTensorV2()\n",
        "    ])\n",
        "\n",
        "print(\"✓ Dataset class and transforms defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oarz-JQAA9Ef",
        "outputId": "0463ec0e-d6c9-4b80-d98b-5b4043a27407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model architecture defined\n",
            "Random seed for weight initialization: 42\n"
          ]
        }
      ],
      "source": [
        "# Model architecture\n",
        "class ResNet50Classifier(nn.Module):\n",
        "    def __init__(self, num_classes: int = 2, pretrained: bool = True, dropout: float = 0.3):\n",
        "        super().__init__()\n",
        "        \n",
        "        weights = ResNet50_Weights.IMAGENET1K_V2 if pretrained else None\n",
        "        self.backbone = models.resnet50(weights=weights)\n",
        "        num_features = self.backbone.fc.in_features  # 2048\n",
        "        self.backbone.fc = nn.Identity()\n",
        "        \n",
        "        # IMPROVED head: 2048 → 2048 → 1024 → 512 → 2 (added capacity)\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Dropout(dropout),  # 0.3 - more permissive\n",
        "            nn.Linear(num_features, 2048),  # 2048 → 2048 (EXPANDED)\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(2048),\n",
        "            nn.Dropout(dropout * 0.5),  # 0.15\n",
        "            nn.Linear(2048, 1024),  # 2048 → 1024 (NEW intermediate layer)\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.Dropout(dropout * 0.5),  # 0.15\n",
        "            nn.Linear(1024, 512),  # 1024 → 512\n",
        "            nn.ReLU(),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.Dropout(dropout * 0.25),  # 0.075 - lighter at end\n",
        "            nn.Linear(512, num_classes)  # 512 → 2\n",
        "        )\n",
        "    \n",
        "    def forward(self, x: torch.Tensor):\n",
        "        features = self.backbone(x)\n",
        "        logits = self.head(features)\n",
        "        return logits, features\n",
        "\n",
        "\n",
        "# Focal Loss for class imbalance\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha: Optional[torch.Tensor] = None, gamma: float = 1.8,  # TUNED\n",
        "                 reduction: str = 'mean', label_smoothing: float = 0.1):  # NEW\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma  # 1.8 - less aggressive\n",
        "        self.reduction = reduction\n",
        "        self.label_smoothing = label_smoothing  # NEW for calibration\n",
        "    \n",
        "    def forward(self, inputs: torch.Tensor, targets: torch.Tensor) -> torch.Tensor:\n",
        "        # Apply label smoothing if enabled\n",
        "        if self.label_smoothing > 0:\n",
        "            n_classes = inputs.size(1)\n",
        "            targets_smooth = targets.float()\n",
        "            targets_smooth = targets_smooth * (1 - self.label_smoothing) + self.label_smoothing / n_classes\n",
        "        \n",
        "        ce_loss = F.cross_entropy(inputs, targets, weight=self.alpha, reduction='none')\n",
        "        pt = torch.exp(-ce_loss)\n",
        "        focal_loss = ((1 - pt) ** self.gamma) * ce_loss\n",
        "        \n",
        "        if self.reduction == 'mean':\n",
        "            return focal_loss.mean()\n",
        "        return focal_loss.sum()\n",
        "\n",
        "# Temperature scaling\n",
        "class TemperatureScaler(nn.Module):\n",
        "    \"\"\"Temperature scaling for calibration.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.log_temperature = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "    @property\n",
        "    def temperature(self) -> torch.Tensor:\n",
        "        return self.log_temperature.exp()\n",
        "\n",
        "    def forward(self, logits: torch.Tensor) -> torch.Tensor:\n",
        "        return logits / self.temperature\n",
        "\n",
        "print(\"✓ Model architecture defined\")\n",
        "print(f\"Random seed for weight initialization: {SEED}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 64\n",
            "Dropout: 0.3\n",
            "Head LR: 0.005\n",
            "Max Epochs: 150\n",
            "Head Parameters: 6827522\n",
            "Focal Loss Gamma: 1.8\n",
            "Label Smoothing: 0.1\n"
          ]
        }
      ],
      "source": [
        "# After loading the improved notebook, check config values:\n",
        "print(f\"Batch Size: {config.BATCH_SIZE}\")  # Should be 64\n",
        "print(f\"Dropout: {config.DROPOUT}\")        # Should be 0.3\n",
        "print(f\"Head LR: {config.HEAD_LR}\")        # Should be 5e-3\n",
        "print(f\"Max Epochs: {config.MAX_EPOCHS}\")  # Should be 150\n",
        "\n",
        "# Count model parameters:\n",
        "model = ResNet50Classifier(config.NUM_CLASSES, config.PRETRAINED, config.DROPOUT)\n",
        "head_params = sum(p.numel() for p in model.head.parameters())\n",
        "print(f\"Head Parameters: {head_params}\")  # Should be ~3.4M (was 2.6M)\n",
        "\n",
        "# Check loss function:\n",
        "criterion = FocalLoss(alpha=None, gamma=1.8, label_smoothing=0.1)\n",
        "print(f\"Focal Loss Gamma: {criterion.gamma}\")  # Should be 1.8\n",
        "print(f\"Label Smoothing: {criterion.label_smoothing}\")  # Should be 0.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dx3gWbbfA9Ef",
        "outputId": "34c2c3af-198b-41b0-b332-e0c8b4216c1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Training utilities defined\n"
          ]
        }
      ],
      "source": [
        "# Training utilities\n",
        "def get_layer_groups(model: nn.Module) -> List[List[nn.Parameter]]:\n",
        "    \"\"\"Get parameter groups for discriminative fine-tuning.\"\"\"\n",
        "    groups = []\n",
        "\n",
        "    # Layer 4 (deepest)\n",
        "    groups.append(list(model.backbone.layer4.parameters()))\n",
        "    # Layer 3\n",
        "    groups.append(list(model.backbone.layer3.parameters()))\n",
        "    # Layer 2\n",
        "    groups.append(list(model.backbone.layer2.parameters()))\n",
        "    # Layer 1\n",
        "    groups.append(list(model.backbone.layer1.parameters()))\n",
        "    # Conv1 + BN\n",
        "    groups.append(list(model.backbone.conv1.parameters()) + list(model.backbone.bn1.parameters()))\n",
        "\n",
        "    return groups\n",
        "\n",
        "def build_optimizer_warmup(model: nn.Module, config: Config) -> optim.Optimizer:\n",
        "    \"\"\"Build optimizer for warmup (head only).\"\"\"\n",
        "    return optim.AdamW(model.head.parameters(), lr=config.HEAD_LR, weight_decay=config.WEIGHT_DECAY)\n",
        "\n",
        "def build_optimizer_finetune(model: nn.Module, config: Config) -> optim.Optimizer:\n",
        "    \"\"\"Build optimizer with discriminative learning rates.\"\"\"\n",
        "    param_groups = [\n",
        "        {'params': model.head.parameters(), 'lr': config.HEAD_LR},\n",
        "    ]\n",
        "\n",
        "    layer_groups = get_layer_groups(model)\n",
        "    lrs = [config.BACKBONE_LR_HIGH, config.BACKBONE_LR_HIGH, config.BACKBONE_LR_MID,\n",
        "           config.BACKBONE_LR_MID, config.BACKBONE_LR_LOW]\n",
        "\n",
        "    for params, lr in zip(layer_groups, lrs):\n",
        "        param_groups.append({'params': params, 'lr': lr})\n",
        "\n",
        "    return optim.AdamW(param_groups, weight_decay=config.WEIGHT_DECAY)\n",
        "\n",
        "def freeze_backbone(model: nn.Module):\n",
        "    \"\"\"Freeze backbone parameters.\"\"\"\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "def unfreeze_backbone(model: nn.Module):\n",
        "    \"\"\"Unfreeze backbone parameters.\"\"\"\n",
        "    for param in model.backbone.parameters():\n",
        "        param.requires_grad = True\n",
        "\n",
        "def cosine_annealing(epoch: int, max_epochs: int, base_lr: float) -> float:\n",
        "    \"\"\"Cosine annealing schedule.\"\"\"\n",
        "    return base_lr * 0.5 * (1 + np.cos(np.pi * epoch / max_epochs))\n",
        "\n",
        "def warmup_lr(epoch: int, warmup_epochs: int, base_lr: float) -> float:\n",
        "    \"\"\"Warmup learning rate schedule.\"\"\"\n",
        "    if epoch < warmup_epochs:\n",
        "        return base_lr * (epoch + 1) / warmup_epochs\n",
        "    return base_lr\n",
        "\n",
        "print(\"✓ Training utilities defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dnGLQCLOA9Ef",
        "outputId": "247221c5-f745-4bc9-bb68-84293e0a7875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Training and evaluation functions defined\n"
          ]
        }
      ],
      "source": [
        "# Training and evaluation functions\n",
        "def train_epoch(model: nn.Module, loader: DataLoader, criterion: nn.Module,\n",
        "                optimizer: optim.Optimizer, device: str, gradient_clip: float = 1.0) -> Tuple[float, float]:\n",
        "    \"\"\"Train for one epoch with gradient clipping.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    pbar = tqdm(loader, desc='Training')\n",
        "    for batch in pbar:\n",
        "        images = batch['image'].to(device)\n",
        "        labels = batch['label'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits, _ = model(images)\n",
        "        loss = criterion(logits, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        if gradient_clip > 0:\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), max_norm=gradient_clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * images.size(0)\n",
        "        _, preds = logits.max(1)\n",
        "        correct += preds.eq(labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "        pbar.set_postfix({'loss': total_loss / total, 'acc': 100 * correct / total})\n",
        "\n",
        "    return total_loss / total, correct / total\n",
        "\n",
        "def validate(model: nn.Module, loader: DataLoader, criterion: nn.Module, device: str) -> Tuple[float, float, float]:\n",
        "    \"\"\"Validate model.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Validation'):\n",
        "            images = batch['image'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits, _ = model(images)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "            total_loss += loss.item() * images.size(0)\n",
        "            _, preds = logits.max(1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_loss = total_loss / len(loader.dataset)\n",
        "    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))\n",
        "    f1 = f1_score(all_labels, all_preds, zero_division=0)\n",
        "\n",
        "    return avg_loss, accuracy, f1\n",
        "\n",
        "def evaluate(model: nn.Module, loader: DataLoader, device: str) -> Dict[str, Any]:\n",
        "    \"\"\"Full evaluation with all metrics.\"\"\"\n",
        "    model.eval()\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(loader, desc='Evaluating'):\n",
        "            images = batch['image'].to(device)\n",
        "            labels = batch['label'].to(device)\n",
        "\n",
        "            logits, _ = model(images)\n",
        "            probs = torch.softmax(logits, dim=1)\n",
        "            _, preds = probs.max(1)\n",
        "\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_probs.extend(probs[:, 1].cpu().numpy())\n",
        "\n",
        "    all_preds = np.array(all_preds)\n",
        "    all_labels = np.array(all_labels)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "    # Per-class metrics\n",
        "    report = classification_report(all_labels, all_preds, output_dict=True, zero_division=0)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(all_labels, all_preds),\n",
        "        'precision': precision_score(all_labels, all_preds, zero_division=0),\n",
        "        'recall': recall_score(all_labels, all_preds, zero_division=0),\n",
        "        'f1': f1_score(all_labels, all_preds, zero_division=0),\n",
        "        'roc_auc': roc_auc_score(all_labels, all_probs),\n",
        "        'confusion_matrix': cm,\n",
        "        'predictions': all_preds,\n",
        "        'labels': all_labels,\n",
        "        'probabilities': all_probs,\n",
        "        'report': report\n",
        "    }\n",
        "\n",
        "print(\"✓ Training and evaluation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mCFOW7MuA9Eg",
        "outputId": "d8d00134-39ca-47b3-e0ed-74db4cef7946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Single fold training function defined\n"
          ]
        }
      ],
      "source": [
        "# Main training pipeline\n",
        "def train_single_fold(model: nn.Module, train_loader: DataLoader, val_loader: DataLoader,\n",
        "                     config: Config, device: str, fold_idx: int) -> Tuple[float, Dict[str, Any]]:\n",
        "    \"\"\"Train model on single fold.\"\"\"\n",
        "\n",
        "    # Compute class weights\n",
        "    train_labels = []\n",
        "    for batch in train_loader:\n",
        "        train_labels.extend(batch['label'].numpy())\n",
        "    train_labels = np.array(train_labels)\n",
        "\n",
        "    class_counts = np.bincount(train_labels)\n",
        "    class_weights = len(train_labels) / (len(class_counts) * class_counts)\n",
        "    class_weights = torch.FloatTensor(class_weights).to(device)\n",
        "\n",
        "    print(f\"\\\\nFold {fold_idx+1} - Class weights: {class_weights.cpu().numpy()}\")\n",
        "\n",
        "    criterion = FocalLoss(alpha=class_weights, gamma=2.0)\n",
        "\n",
        "    # Warmup phase\n",
        "    freeze_backbone(model)\n",
        "    optimizer = build_optimizer_warmup(model, config)\n",
        "\n",
        "    best_val_f1 = 0.0\n",
        "    patience_counter = 0\n",
        "    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': []}\n",
        "\n",
        "    print(f\"\\\\n--- WARMUP PHASE (Epochs 1-{config.WARMUP_EPOCHS}) ---\")\n",
        "    for epoch in range(config.WARMUP_EPOCHS):\n",
        "        lr = warmup_lr(epoch, config.WARMUP_EPOCHS, config.HEAD_LR)\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, config.GRADIENT_CLIP)\n",
        "        val_loss, val_acc, val_f1 = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        print(f\"Ep {epoch+1}: TrLoss={train_loss:.4f} TrAcc={train_acc:.4f} VlLoss={val_loss:.4f} VlAcc={val_acc:.4f} VlF1={val_f1:.4f} LR={lr:.6f}\")\n",
        "\n",
        "    # Fine-tuning phase\n",
        "    print(f\"\\\\n--- FINE-TUNING PHASE (Progressive unfreezing) ---\")\n",
        "    unfreeze_backbone(model)\n",
        "    optimizer = build_optimizer_finetune(model, config)\n",
        "\n",
        "    for epoch in range(config.WARMUP_EPOCHS, config.MAX_EPOCHS):\n",
        "        # Cosine annealing for each param group\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = cosine_annealing(epoch - config.WARMUP_EPOCHS,\n",
        "                                                 config.MAX_EPOCHS - config.WARMUP_EPOCHS,\n",
        "                                                 param_group['lr'])\n",
        "\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, config.GRADIENT_CLIP)\n",
        "        val_loss, val_acc, val_f1 = validate(model, val_loader, criterion, device)\n",
        "\n",
        "        history['train_loss'].append(train_loss)\n",
        "        history['train_acc'].append(train_acc)\n",
        "        history['val_loss'].append(val_loss)\n",
        "        history['val_acc'].append(val_acc)\n",
        "        history['val_f1'].append(val_f1)\n",
        "\n",
        "        if epoch % 5 == 0:\n",
        "            print(f\"Ep {epoch+1}: TrLoss={train_loss:.4f} TrAcc={train_acc:.4f} VlLoss={val_loss:.4f} VlAcc={val_acc:.4f} VlF1={val_f1:.4f}\")\n",
        "\n",
        "        if val_f1 > best_val_f1:\n",
        "            best_val_f1 = val_f1\n",
        "            patience_counter = 0\n",
        "            checkpoint_path = os.path.join(config.CHECKPOINT_DIR, f'fold_{fold_idx}_best.pth')\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        if patience_counter >= config.EARLY_STOPPING_PATIENCE:\n",
        "            print(f\"\\\\n✓ Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "    # Load best model\n",
        "    checkpoint_path = os.path.join(config.CHECKPOINT_DIR, f'fold_{fold_idx}_best.pth')\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "\n",
        "    # Final evaluation\n",
        "    val_metrics = evaluate(model, val_loader, device)\n",
        "\n",
        "    return best_val_f1, val_metrics\n",
        "\n",
        "print(\"✓ Single fold training function defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BfKAsNhXA9Eg",
        "outputId": "bc443eaf-dee2-499b-a5be-e8909b5aa057"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Cross-validation functions defined\n"
          ]
        }
      ],
      "source": [
        "# Cross-validation and bootstrapping\n",
        "def bootstrap_ci(metric_values: np.ndarray, n_samples: int = 1000, ci: float = 0.95) -> Tuple[float, float, float]:\n",
        "    \"\"\"Compute bootstrap confidence interval.\"\"\"\n",
        "    bootstrapped = []\n",
        "    for _ in range(n_samples):\n",
        "        indices = np.random.choice(len(metric_values), size=len(metric_values), replace=True)\n",
        "        bootstrapped.append(np.mean(metric_values[indices]))\n",
        "\n",
        "    bootstrapped = np.array(bootstrapped)\n",
        "    mean = np.mean(bootstrapped)\n",
        "    alpha = 1 - ci\n",
        "    lower = np.percentile(bootstrapped, alpha/2 * 100)\n",
        "    upper = np.percentile(bootstrapped, (1 - alpha/2) * 100)\n",
        "\n",
        "    return mean, lower, upper\n",
        "\n",
        "def stratified_kfold_cv(df: pd.DataFrame, config: Config, device: str) -> Dict[str, Any]:\n",
        "    \"\"\"Perform stratified k-fold cross-validation.\"\"\"\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=config.N_SPLITS, shuffle=True, random_state=config.RANDOM_STATE)\n",
        "\n",
        "    fold_results = []\n",
        "    all_test_preds = []\n",
        "    all_test_labels = []\n",
        "    all_test_probs = []\n",
        "\n",
        "    for fold_idx, (train_idx, test_idx) in enumerate(skf.split(df, df['binary_label'])):\n",
        "        print(f\"\\\\n{'='*70}\")\n",
        "        print(f\"FOLD {fold_idx + 1}/{config.N_SPLITS}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        train_df = df.iloc[train_idx].reset_index(drop=True)\n",
        "        test_df = df.iloc[test_idx].reset_index(drop=True)\n",
        "\n",
        "        # Further split train into train/val\n",
        "        train_df, val_df = train_test_split(train_df, test_size=0.2,\n",
        "                                           random_state=config.RANDOM_STATE,\n",
        "                                           stratify=train_df['binary_label'])\n",
        "\n",
        "        # Create datasets and loaders\n",
        "        train_dataset = SkinCancerDataset(train_df, get_train_transforms(config.IMG_SIZE))\n",
        "        val_dataset = SkinCancerDataset(val_df, get_val_transforms(config.IMG_SIZE))\n",
        "        test_dataset = SkinCancerDataset(test_df, get_val_transforms(config.IMG_SIZE))\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True, num_workers=config.NUM_WORKERS)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS)\n",
        "        test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=config.NUM_WORKERS)\n",
        "\n",
        "        print(f\"Train: {len(train_df)} | Val: {len(val_df)} | Test: {len(test_df)}\")\n",
        "        print(f\"Train melanoma: {(train_df['binary_label'] == 1).sum()} | Non-melanoma: {(train_df['binary_label'] == 0).sum()}\")\n",
        "\n",
        "        # Create and train model\n",
        "        model = ResNet50Classifier(config.NUM_CLASSES, config.PRETRAINED, config.DROPOUT)\n",
        "        model = model.to(device)\n",
        "\n",
        "        best_f1, val_metrics = train_single_fold(model, train_loader, val_loader, config, device, fold_idx)\n",
        "\n",
        "        # Test evaluation\n",
        "        test_metrics = evaluate(model, test_loader, device)\n",
        "\n",
        "        fold_results.append({\n",
        "            'fold': fold_idx,\n",
        "            'val_metrics': val_metrics,\n",
        "            'test_metrics': test_metrics\n",
        "        })\n",
        "\n",
        "        all_test_preds.extend(test_metrics['predictions'])\n",
        "        all_test_labels.extend(test_metrics['labels'])\n",
        "        all_test_probs.extend(test_metrics['probabilities'])\n",
        "\n",
        "        print(f\"\\\\n✓ Fold {fold_idx+1} completed\")\n",
        "        print(f\"Test F1: {test_metrics['f1']:.4f} | Test AUC: {test_metrics['roc_auc']:.4f}\")\n",
        "\n",
        "    all_test_preds = np.array(all_test_preds)\n",
        "    all_test_labels = np.array(all_test_labels)\n",
        "    all_test_probs = np.array(all_test_probs)\n",
        "\n",
        "    # Aggregate metrics with bootstrap CI\n",
        "    f1_scores = [fold_results[i]['test_metrics']['f1'] for i in range(len(fold_results))]\n",
        "    auc_scores = [fold_results[i]['test_metrics']['roc_auc'] for i in range(len(fold_results))]\n",
        "\n",
        "    aggregated = {\n",
        "        'fold_results': fold_results,\n",
        "        'all_test_predictions': all_test_preds,\n",
        "        'all_test_labels': all_test_labels,\n",
        "        'all_test_probabilities': all_test_probs,\n",
        "        'f1_mean': np.mean(f1_scores),\n",
        "        'f1_std': np.std(f1_scores),\n",
        "        'auc_mean': np.mean(auc_scores),\n",
        "        'auc_std': np.std(auc_scores)\n",
        "    }\n",
        "\n",
        "    # Bootstrap CIs\n",
        "    f1_mean, f1_lower, f1_upper = bootstrap_ci(np.array(f1_scores), config.N_BOOTSTRAP_SAMPLES, config.CI_LEVEL)\n",
        "    auc_mean, auc_lower, auc_upper = bootstrap_ci(np.array(auc_scores), config.N_BOOTSTRAP_SAMPLES, config.CI_LEVEL)\n",
        "\n",
        "    aggregated['f1_ci'] = (f1_lower, f1_upper)\n",
        "    aggregated['auc_ci'] = (auc_lower, auc_upper)\n",
        "\n",
        "    return aggregated\n",
        "\n",
        "print(\"✓ Cross-validation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGLl7UuIA9Eg",
        "outputId": "9ff17fe0-c66f-42dc-a53a-b627269c992a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Clinical validation functions defined\n"
          ]
        }
      ],
      "source": [
        "# Clinical validation and error analysis\n",
        "def per_class_metrics(predictions: np.ndarray, labels: np.ndarray, probabilities: np.ndarray) -> Dict[str, Any]:\n",
        "    \"\"\"Compute per-class metrics and check clinical thresholds.\"\"\"\n",
        "\n",
        "    metrics_by_class = {}\n",
        "    class_names = {0: 'Non-Melanoma', 1: 'Melanoma'}\n",
        "\n",
        "    for class_idx in [0, 1]:\n",
        "        mask = labels == class_idx\n",
        "        if mask.sum() == 0:\n",
        "            continue\n",
        "\n",
        "        class_preds = predictions[mask]\n",
        "        class_labels = labels[mask]\n",
        "        class_probs = probabilities[mask]\n",
        "\n",
        "        metrics_by_class[class_names[class_idx]] = {\n",
        "            'count': mask.sum(),\n",
        "            'precision': precision_score(class_labels, class_preds, pos_label=class_idx, zero_division=0),\n",
        "            'recall': recall_score(class_labels, class_preds, pos_label=class_idx, zero_division=0),\n",
        "            'f1': f1_score(class_labels, class_preds, pos_label=class_idx, zero_division=0),\n",
        "            'auc': roc_auc_score((class_labels == class_idx).astype(int), class_probs) if len(np.unique(class_labels)) > 1 else np.nan\n",
        "        }\n",
        "\n",
        "    return metrics_by_class\n",
        "\n",
        "def clinical_validation(metrics_by_class: Dict[str, Any]) -> Dict[str, bool]:\n",
        "    \"\"\"Check if models meet clinical performance requirements.\"\"\"\n",
        "\n",
        "    validation_status = {}\n",
        "\n",
        "    if 'Melanoma' in metrics_by_class:\n",
        "        melanoma_f1 = metrics_by_class['Melanoma']['f1']\n",
        "        passed = melanoma_f1 >= config.MIN_MELANOMA_F1\n",
        "        validation_status['Melanoma F1 >= 0.90'] = passed\n",
        "        print(f\"\\\\n{'='*70}\")\n",
        "        print(f\"CLINICAL VALIDATION REPORT\")\n",
        "        print(f\"{'='*70}\")\n",
        "        print(f\"Melanoma F1 Score: {melanoma_f1:.4f}\")\n",
        "        print(f\"Requirement: >= {config.MIN_MELANOMA_F1}\")\n",
        "        print(f\"Status: {'✓ PASSED' if passed else '✗ FAILED'}\")\n",
        "\n",
        "    return validation_status\n",
        "\n",
        "def error_analysis(predictions: np.ndarray, labels: np.ndarray, probabilities: np.ndarray) -> Dict[str, Any]:\n",
        "    \"\"\"Analyze model errors.\"\"\"\n",
        "\n",
        "    errors = predictions != labels\n",
        "\n",
        "    # False positives: predicted 1, actual 0\n",
        "    fp_mask = (predictions == 1) & (labels == 0)\n",
        "    # False negatives: predicted 0, actual 1\n",
        "    fn_mask = (predictions == 0) & (labels == 1)\n",
        "\n",
        "    fp_probs = probabilities[fp_mask]\n",
        "    fn_probs = probabilities[fn_mask]\n",
        "\n",
        "    return {\n",
        "        'total_errors': errors.sum(),\n",
        "        'error_rate': errors.mean(),\n",
        "        'false_positives': fp_mask.sum(),\n",
        "        'false_negatives': fn_mask.sum(),\n",
        "        'avg_fp_confidence': fp_probs.mean() if len(fp_probs) > 0 else 0,\n",
        "        'avg_fn_confidence': 1 - fn_probs.mean() if len(fn_probs) > 0 else 0,\n",
        "    }\n",
        "\n",
        "print(\"✓ Clinical validation functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Model complexity analysis utilities defined\n"
          ]
        }
      ],
      "source": [
        "# Model complexity analysis utilities\n",
        "def count_parameters(model: nn.Module) -> Dict[str, int]:\n",
        "    \"\"\"Count model parameters.\"\"\"\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    non_trainable_params = total_params - trainable_params\n",
        "    \n",
        "    return {\n",
        "        'total_params': total_params,\n",
        "        'trainable_params': trainable_params,\n",
        "        'non_trainable_params': non_trainable_params,\n",
        "        'total_params_millions': total_params / 1e6,\n",
        "        'model_size_mb': (total_params * 4) / (1024**2)  # Assuming float32\n",
        "    }\n",
        "\n",
        "def estimate_flops(model: nn.Module, input_size: Tuple[int, int, int, int]) -> float:\n",
        "    \"\"\"Estimate FLOPs for the model (approximate).\"\"\"\n",
        "    # Create a dummy input\n",
        "    dummy_input = torch.randn(input_size).to(next(model.parameters()).device)\n",
        "    \n",
        "    # Count operations (simplified estimation)\n",
        "    total_ops = 0\n",
        "    \n",
        "    def count_conv2d(m, x, y):\n",
        "        nonlocal total_ops\n",
        "        kernel_ops = m.kernel_size[0] * m.kernel_size[1] * m.in_channels\n",
        "        output_elements = y.numel()\n",
        "        total_ops += kernel_ops * output_elements\n",
        "    \n",
        "    def count_linear(m, x, y):\n",
        "        nonlocal total_ops\n",
        "        total_ops += m.in_features * m.out_features\n",
        "    \n",
        "    # Register hooks\n",
        "    hooks = []\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            hooks.append(module.register_forward_hook(count_conv2d))\n",
        "        elif isinstance(module, nn.Linear):\n",
        "            hooks.append(module.register_forward_hook(count_linear))\n",
        "    \n",
        "    # Forward pass\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        _ = model(dummy_input)\n",
        "    \n",
        "    # Remove hooks\n",
        "    for hook in hooks:\n",
        "        hook.remove()\n",
        "    \n",
        "    return total_ops / 1e9  # Return in GFLOPs\n",
        "\n",
        "def measure_inference_time(model: nn.Module, loader: DataLoader, device: str, num_batches: int = 10) -> Dict[str, float]:\n",
        "    \"\"\"Measure inference time and throughput.\"\"\"\n",
        "    model.eval()\n",
        "    times = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i, batch in enumerate(loader):\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "            \n",
        "            images = batch['image'].to(device)\n",
        "            batch_size = images.size(0)\n",
        "            \n",
        "            # Warm up CUDA\n",
        "            if i == 0 and torch.cuda.is_available():\n",
        "                _ = model(images)\n",
        "                torch.cuda.synchronize()\n",
        "            \n",
        "            start = time.time()\n",
        "            _ = model(images)\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            end = time.time()\n",
        "            \n",
        "            times.append((end - start) / batch_size)  # Time per sample\n",
        "    \n",
        "    avg_time_per_sample = np.mean(times)\n",
        "    throughput = 1.0 / avg_time_per_sample  # Samples per second\n",
        "    \n",
        "    return {\n",
        "        'avg_inference_time_per_sample_ms': avg_time_per_sample * 1000,\n",
        "        'avg_inference_time_per_sample_s': avg_time_per_sample,\n",
        "        'throughput_samples_per_second': throughput,\n",
        "        'latency_ms': np.mean([t * 1000 for t in times])\n",
        "    }\n",
        "\n",
        "print(\"✓ Model complexity analysis utilities defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Visualization functions defined\n"
          ]
        }
      ],
      "source": [
        "# Monitoring utilities for time, memory, power, and energy\n",
        "import time\n",
        "import psutil\n",
        "import threading\n",
        "from collections import defaultdict\n",
        "\n",
        "try:\n",
        "    import pynvml\n",
        "    pynvml.nvmlInit()\n",
        "    NVML_AVAILABLE = True\n",
        "except:\n",
        "    NVML_AVAILABLE = False\n",
        "    print(\"⚠️  NVML not available. GPU power monitoring will be disabled.\")\n",
        "\n",
        "class ResourceMonitor:\n",
        "    \"\"\"Monitor time, memory, power, and energy consumption.\"\"\"\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.start_time = None\n",
        "        self.end_time = None\n",
        "        self.gpu_power_samples = []\n",
        "        self.memory_samples = []\n",
        "        self.monitoring = False\n",
        "        self.monitor_thread = None\n",
        "        \n",
        "    def start(self):\n",
        "        \"\"\"Start monitoring resources.\"\"\"\n",
        "        self.start_time = time.time()\n",
        "        self.gpu_power_samples = []\n",
        "        self.memory_samples = []\n",
        "        self.monitoring = True\n",
        "        \n",
        "        # Start background monitoring thread\n",
        "        self.monitor_thread = threading.Thread(target=self._monitor_loop, daemon=True)\n",
        "        self.monitor_thread.start()\n",
        "        \n",
        "    def stop(self):\n",
        "        \"\"\"Stop monitoring resources.\"\"\"\n",
        "        self.end_time = time.time()\n",
        "        self.monitoring = False\n",
        "        if self.monitor_thread:\n",
        "            self.monitor_thread.join(timeout=2.0)\n",
        "        \n",
        "    def _monitor_loop(self):\n",
        "        \"\"\"Background loop to collect power and memory samples.\"\"\"\n",
        "        while self.monitoring:\n",
        "            try:\n",
        "                # GPU Memory\n",
        "                if torch.cuda.is_available():\n",
        "                    gpu_mem = torch.cuda.memory_allocated() / (1024**3)  # GB\n",
        "                    self.memory_samples.append(gpu_mem)\n",
        "                \n",
        "                # GPU Power (if available)\n",
        "                if NVML_AVAILABLE:\n",
        "                    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "                    power_mw = pynvml.nvmlDeviceGetPowerUsage(handle)  # milliwatts\n",
        "                    power_w = power_mw / 1000.0  # watts\n",
        "                    self.gpu_power_samples.append(power_w)\n",
        "                    \n",
        "            except Exception as e:\n",
        "                pass\n",
        "            \n",
        "            time.sleep(0.5)  # Sample every 500ms\n",
        "    \n",
        "    def get_metrics(self) -> Dict[str, Any]:\n",
        "        \"\"\"Calculate and return all metrics.\"\"\"\n",
        "        if self.start_time is None or self.end_time is None:\n",
        "            return {}\n",
        "        \n",
        "        elapsed_time = self.end_time - self.start_time\n",
        "        \n",
        "        metrics = {\n",
        "            'elapsed_time_seconds': elapsed_time,\n",
        "            'elapsed_time_minutes': elapsed_time / 60.0,\n",
        "            'elapsed_time_hours': elapsed_time / 3600.0,\n",
        "        }\n",
        "        \n",
        "        # Memory metrics\n",
        "        if self.memory_samples:\n",
        "            metrics['gpu_memory_avg_gb'] = np.mean(self.memory_samples)\n",
        "            metrics['gpu_memory_max_gb'] = np.max(self.memory_samples)\n",
        "            metrics['gpu_memory_min_gb'] = np.min(self.memory_samples)\n",
        "        \n",
        "        if torch.cuda.is_available():\n",
        "            metrics['gpu_memory_peak_gb'] = torch.cuda.max_memory_allocated() / (1024**3)\n",
        "        \n",
        "        # Power and energy metrics\n",
        "        if self.gpu_power_samples:\n",
        "            avg_power_w = np.mean(self.gpu_power_samples)\n",
        "            max_power_w = np.max(self.gpu_power_samples)\n",
        "            min_power_w = np.min(self.gpu_power_samples)\n",
        "            \n",
        "            # Energy = Power × Time\n",
        "            energy_wh = (avg_power_w * elapsed_time) / 3600.0  # Watt-hours\n",
        "            energy_kwh = energy_wh / 1000.0  # Kilowatt-hours\n",
        "            \n",
        "            metrics['gpu_power_avg_watts'] = avg_power_w\n",
        "            metrics['gpu_power_max_watts'] = max_power_w\n",
        "            metrics['gpu_power_min_watts'] = min_power_w\n",
        "            metrics['gpu_energy_wh'] = energy_wh\n",
        "            metrics['gpu_energy_kwh'] = energy_kwh\n",
        "        \n",
        "        return metrics\n",
        "\n",
        "print(\"✓ Resource monitoring utilities defined\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiS-IzAXA9Eg",
        "outputId": "e6f40e89-b7ca-4e92-8147-f505f9c6a7e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Visualization functions defined\n"
          ]
        }
      ],
      "source": [
        "# Visualization functions\n",
        "def plot_confusion_matrix(cm: np.ndarray, save_path: str):\n",
        "    \"\"\"Plot confusion matrix.\"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Non-Melanoma', 'Melanoma'],\n",
        "                yticklabels=['Non-Melanoma', 'Melanoma'])\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_roc_curve(labels: np.ndarray, probs: np.ndarray, save_path: str):\n",
        "    \"\"\"Plot ROC curve.\"\"\"\n",
        "    fpr, tpr, _ = roc_curve(labels, probs)\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, lw=2, label=f'ROC Curve (AUC = {roc_auc:.3f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random')\n",
        "    plt.xlim([0, 1])\n",
        "    plt.ylim([0, 1.05])\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "def plot_training_history(history_dict: Dict[str, List[float]], save_path: str):\n",
        "    \"\"\"Plot training history.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "    axes[0].plot(history_dict['train_loss'], label='Train Loss')\n",
        "    axes[0].plot(history_dict['val_loss'], label='Val Loss')\n",
        "    axes[0].set_xlabel('Epoch')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Training and Validation Loss')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    axes[1].plot(history_dict['train_acc'], label='Train Acc')\n",
        "    axes[1].plot(history_dict['val_acc'], label='Val Acc')\n",
        "    axes[1].plot(history_dict['val_f1'], label='Val F1')\n",
        "    axes[1].set_xlabel('Epoch')\n",
        "    axes[1].set_ylabel('Score')\n",
        "    axes[1].set_title('Training Metrics')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.close()\n",
        "\n",
        "print(\"✓ Visualization functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======================================================================\n",
            "SKIN CANCER CLASSIFICATION PIPELINE\n",
            "======================================================================\n",
            "Device: cuda\n",
            "Model: resnet50\n",
            "Random Seed: 42\n",
            "Image Size: 224x224\n",
            "Batch Size: 64\n",
            "N-Fold CV: 5\n",
            "======================================================================\n",
            "\n",
            "\n",
            "✓ Dataset loaded: 10015 samples\n",
            "Class distribution:\n",
            "binary_label\n",
            "0    8902\n",
            "1    1113\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "======================================================================\n",
            "1. COMPUTATIONAL COMPLEXITY\n",
            "======================================================================\n",
            "\n",
            "Model Parameters:\n",
            "  Total Parameters: 30,335,554\n",
            "  Trainable Parameters: 30,335,554\n",
            "  Non-trainable Parameters: 0\n",
            "  Parameters (Millions): 30.34M\n",
            "\n",
            "Computational Cost:\n",
            "  FLOPs per inference: 4.09 GFLOPs\n",
            "\n",
            "Inference Performance:\n"
          ]
        },
        {
          "ename": "NameError",
          "evalue": "name 'time' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[35], line 49\u001b[0m\n\u001b[0;32m     46\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m SkinCancerDataset(test_subset, get_val_transforms(config\u001b[38;5;241m.\u001b[39mIMG_SIZE))\n\u001b[0;32m     47\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 49\u001b[0m inference_metrics \u001b[38;5;241m=\u001b[39m measure_inference_time(sample_model, test_loader, config\u001b[38;5;241m.\u001b[39mDEVICE, num_batches\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Average Latency: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatency_ms\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ms per sample\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Throughput: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minference_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthroughput_samples_per_second\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples/second\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[31], line 71\u001b[0m, in \u001b[0;36mmeasure_inference_time\u001b[1;34m(model, loader, device, num_batches)\u001b[0m\n\u001b[0;32m     68\u001b[0m     _ \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     69\u001b[0m     torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39msynchronize()\n\u001b[1;32m---> 71\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     72\u001b[0m _ \u001b[38;5;241m=\u001b[39m model(images)\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n",
            "\u001b[1;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ],
      "source": [
        "# MAIN EXECUTION WITH ENHANCED METRICS\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"SKIN CANCER CLASSIFICATION PIPELINE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"Device: {config.DEVICE}\")\n",
        "print(f\"Model: {config.MODEL_NAME}\")\n",
        "print(f\"Random Seed: {SEED}\")\n",
        "print(f\"Image Size: {config.IMG_SIZE}x{config.IMG_SIZE}\")\n",
        "print(f\"Batch Size: {config.BATCH_SIZE}\")\n",
        "print(f\"N-Fold CV: {config.N_SPLITS}\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "# Load data\n",
        "if not df_isic.empty:\n",
        "    print(f\"\\n✓ Dataset loaded: {len(df_isic)} samples\")\n",
        "    print(f\"Class distribution:\\n{df_isic['binary_label'].value_counts()}\\n\")\n",
        "    \n",
        "    # ========== 1. MODEL COMPLEXITY ANALYSIS ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"1. COMPUTATIONAL COMPLEXITY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    # Create a sample model for analysis\n",
        "    sample_model = ResNet50Classifier(config.NUM_CLASSES, config.PRETRAINED, config.DROPOUT)\n",
        "    sample_model = sample_model.to(config.DEVICE)\n",
        "    \n",
        "    # Count parameters\n",
        "    param_stats = count_parameters(sample_model)\n",
        "    print(f\"\\nModel Parameters:\")\n",
        "    print(f\"  Total Parameters: {param_stats['total_params']:,}\")\n",
        "    print(f\"  Trainable Parameters: {param_stats['trainable_params']:,}\")\n",
        "    print(f\"  Non-trainable Parameters: {param_stats['non_trainable_params']:,}\")\n",
        "    print(f\"  Parameters (Millions): {param_stats['total_params_millions']:.2f}M\")\n",
        "    \n",
        "    # Estimate FLOPs\n",
        "    print(f\"\\nComputational Cost:\")\n",
        "    input_size = (1, 3, config.IMG_SIZE, config.IMG_SIZE)\n",
        "    flops = estimate_flops(sample_model, input_size)\n",
        "    print(f\"  FLOPs per inference: {flops:.2f} GFLOPs\")\n",
        "    \n",
        "    # Measure inference time\n",
        "    print(f\"\\nInference Performance:\")\n",
        "    # Create a small test loader for timing\n",
        "    test_subset = df_isic.head(100)\n",
        "    test_dataset = SkinCancerDataset(test_subset, get_val_transforms(config.IMG_SIZE))\n",
        "    test_loader = DataLoader(test_dataset, batch_size=config.BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "    \n",
        "    inference_metrics = measure_inference_time(sample_model, test_loader, config.DEVICE, num_batches=3)\n",
        "    print(f\"  Average Latency: {inference_metrics['latency_ms']:.2f} ms per sample\")\n",
        "    print(f\"  Throughput: {inference_metrics['throughput_samples_per_second']:.2f} samples/second\")\n",
        "    \n",
        "    # ========== 2. MEMORY COMPLEXITY ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"2. MEMORY COMPLEXITY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    \n",
        "    print(f\"\\nModel Capacity:\")\n",
        "    print(f\"  Model Size (Memory Footprint): {param_stats['model_size_mb']:.2f} MB\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        # Warm-up forward pass\n",
        "        dummy_batch = next(iter(test_loader))\n",
        "        dummy_images = dummy_batch['image'].to(config.DEVICE)\n",
        "        _ = sample_model(dummy_images)\n",
        "        \n",
        "        peak_memory_mb = torch.cuda.max_memory_allocated() / (1024**2)\n",
        "        current_memory_mb = torch.cuda.memory_allocated() / (1024**2)\n",
        "        \n",
        "        print(f\"\\nRuntime Memory Usage (GPU):\")\n",
        "        print(f\"  Current Memory Allocated: {current_memory_mb:.2f} MB\")\n",
        "        print(f\"  Peak Memory Allocated: {peak_memory_mb:.2f} MB\")\n",
        "    \n",
        "    del sample_model, test_loader, test_dataset\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # ========== 3. TRAINING WITH RESOURCE MONITORING ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"3. TRAINING WITH RESOURCE & ENERGY MONITORING\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    # Initialize resource monitor\n",
        "    training_monitor = ResourceMonitor()\n",
        "    training_monitor.start()\n",
        "    \n",
        "    # Track start time\n",
        "    training_start_time = time.time()\n",
        "    \n",
        "    # Run stratified 5-fold CV\n",
        "    cv_results = stratified_kfold_cv(df_isic, config, config.DEVICE)\n",
        "    \n",
        "    # Stop monitoring\n",
        "    training_monitor.stop()\n",
        "    training_end_time = time.time()\n",
        "    \n",
        "    # Get resource metrics\n",
        "    resource_metrics = training_monitor.get_metrics()\n",
        "    \n",
        "    # ========== DISPLAY RESULTS ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"CROSS-VALIDATION RESULTS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"F1 Score: {cv_results['f1_mean']:.4f} ± {cv_results['f1_std']:.4f}\")\n",
        "    print(f\"F1 CI ({int(config.CI_LEVEL*100)}%): [{cv_results['f1_ci'][0]:.4f}, {cv_results['f1_ci'][1]:.4f}]\")\n",
        "    print(f\"\\nROC AUC: {cv_results['auc_mean']:.4f} ± {cv_results['auc_std']:.4f}\")\n",
        "    print(f\"AUC CI ({int(config.CI_LEVEL*100)}%): [{cv_results['auc_ci'][0]:.4f}, {cv_results['auc_ci'][1]:.4f}]\")\n",
        "    \n",
        "    # ========== TIME COMPLEXITY ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TIME COMPLEXITY (TRAINING)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total Training Time: {resource_metrics['elapsed_time_hours']:.2f} hours\")\n",
        "    print(f\"                     ({resource_metrics['elapsed_time_minutes']:.2f} minutes)\")\n",
        "    print(f\"                     ({resource_metrics['elapsed_time_seconds']:.2f} seconds)\")\n",
        "    \n",
        "    # ========== MEMORY USAGE ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"MEMORY USAGE (TRAINING)\")\n",
        "    print(f\"{'='*70}\")\n",
        "    if 'gpu_memory_avg_gb' in resource_metrics:\n",
        "        print(f\"Average GPU Memory Usage: {resource_metrics['gpu_memory_avg_gb']:.2f} GB\")\n",
        "        print(f\"Peak GPU Memory Usage: {resource_metrics['gpu_memory_max_gb']:.2f} GB\")\n",
        "        print(f\"Minimum GPU Memory Usage: {resource_metrics['gpu_memory_min_gb']:.2f} GB\")\n",
        "    \n",
        "    if 'gpu_memory_peak_gb' in resource_metrics:\n",
        "        print(f\"PyTorch Peak Memory: {resource_metrics['gpu_memory_peak_gb']:.2f} GB\")\n",
        "    \n",
        "    # ========== POWER & ENERGY ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"POWER & ENERGY CONSUMPTION\")\n",
        "    print(f\"{'='*70}\")\n",
        "    if 'gpu_power_avg_watts' in resource_metrics:\n",
        "        print(f\"Average GPU Power: {resource_metrics['gpu_power_avg_watts']:.2f} W\")\n",
        "        print(f\"Peak GPU Power: {resource_metrics['gpu_power_max_watts']:.2f} W\")\n",
        "        print(f\"Minimum GPU Power: {resource_metrics['gpu_power_min_watts']:.2f} W\")\n",
        "        print(f\"\\nTotal Energy Consumed: {resource_metrics['gpu_energy_wh']:.2f} Wh\")\n",
        "        print(f\"                       ({resource_metrics['gpu_energy_kwh']:.6f} kWh)\")\n",
        "        \n",
        "        # Calculate CO2 emissions (approximate, using US average: 0.92 lbs CO2/kWh)\n",
        "        co2_lbs = resource_metrics['gpu_energy_kwh'] * 0.92\n",
        "        co2_kg = co2_lbs * 0.453592\n",
        "        print(f\"\\nEstimated CO2 Emissions: {co2_kg:.4f} kg CO2\")\n",
        "    else:\n",
        "        print(\"⚠️  GPU power monitoring not available (pynvml not installed or not supported)\")\n",
        "    \n",
        "    # ========== PER-CLASS METRICS ==========\n",
        "    class_metrics = per_class_metrics(cv_results['all_test_predictions'],\n",
        "                                     cv_results['all_test_labels'],\n",
        "                                     cv_results['all_test_probabilities'])\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"PER-CLASS METRICS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    for class_name, metrics in class_metrics.items():\n",
        "        print(f\"\\n{class_name}:\")\n",
        "        print(f\"  Samples: {metrics['count']}\")\n",
        "        print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "        print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "        print(f\"  F1 Score: {metrics['f1']:.4f}\")\n",
        "        if not np.isnan(metrics['auc']):\n",
        "            print(f\"  AUC: {metrics['auc']:.4f}\")\n",
        "    \n",
        "    # Clinical validation\n",
        "    validation_status = clinical_validation(class_metrics)\n",
        "    \n",
        "    # Error analysis\n",
        "    error_report = error_analysis(cv_results['all_test_predictions'],\n",
        "                                 cv_results['all_test_labels'],\n",
        "                                 cv_results['all_test_probabilities'])\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"ERROR ANALYSIS\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total Errors: {error_report['total_errors']}\")\n",
        "    print(f\"Error Rate: {error_report['error_rate']:.4f}\")\n",
        "    print(f\"False Positives: {error_report['false_positives']} (avg confidence: {error_report['avg_fp_confidence']:.4f})\")\n",
        "    print(f\"False Negatives: {error_report['false_negatives']} (avg confidence: {error_report['avg_fn_confidence']:.4f})\")\n",
        "    \n",
        "    # Visualizations\n",
        "    print(f\"\\nGenerating visualizations...\")\n",
        "    plot_confusion_matrix(confusion_matrix(cv_results['all_test_labels'], cv_results['all_test_predictions']),\n",
        "                        os.path.join(config.RESULTS_DIR, 'confusion_matrix.png'))\n",
        "    plot_roc_curve(cv_results['all_test_labels'], cv_results['all_test_probabilities'],\n",
        "                   os.path.join(config.RESULTS_DIR, 'roc_curve.png'))\n",
        "    \n",
        "    print(f\"✓ Visualizations saved to {config.RESULTS_DIR}\")\n",
        "    \n",
        "    # ========== SUMMARY ==========\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"TRAINING SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"✓ Model: ResNet-50 with {param_stats['total_params_millions']:.2f}M parameters\")\n",
        "    print(f\"✓ Training Time: {resource_metrics['elapsed_time_hours']:.2f} hours\")\n",
        "    print(f\"✓ Test F1 Score: {cv_results['f1_mean']:.4f} ± {cv_results['f1_std']:.4f}\")\n",
        "    print(f\"✓ Test AUC: {cv_results['auc_mean']:.4f} ± {cv_results['auc_std']:.4f}\")\n",
        "    if 'gpu_energy_kwh' in resource_metrics:\n",
        "        print(f\"✓ Energy Consumed: {resource_metrics['gpu_energy_kwh']:.4f} kWh\")\n",
        "    print(f\"\\n✓ Pipeline completed successfully!\")\n",
        "    \n",
        "else:\n",
        "    print(\"\\n⚠️  No data available. Please ensure dataset loading is working.\")\n",
        "    print(\"Dataset should have columns: 'image_path', 'binary_label', 'image_id'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
